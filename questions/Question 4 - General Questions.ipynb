{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "#### Question 1\n",
    "\n",
    "This project dealt with the **localization (L)** part of the SLAM, because we optimized the poses of the pose graph (localization) without building the map of the environment (mapping). Hence, there is no mapping part in this project.\n",
    "\n",
    "The **mapping** part of SLAM mainly deals with building the map of the environment (surronding) simultaneously when optimizing the poses. Given **LiDAR** scans, **RGB** video stream and **noisy** pose data for a moving robot, SLAM optimizes the poses/map. The RGB video stream is used to obtain the **loop closure** constraints for SLAM problem using methods like **Bag of Visual Words (BoVW)**. The global map will be optimized and estimated in each iteration using the LiDAR scans and the optimised pose data.\n",
    "\n",
    "#### Question 2\n",
    "\n",
    "**Loop closures** are important component of SLAM, because these contraints are the ones which pull back the drift in noisy pose data. These constrints are detected using **RGB** video stream, by applying methods like **Bag of Visual Words (BoVW)** which detects the common features in two frames and detects whether it is a loop closure constraint. We can also use many other methods in CV to obtain loop closure constraints, like SIFT etc. The main goal is to detect features in the frames and obtain mapping between frames to find out the loop closure edges.\n",
    "\n",
    "#### Question 3\n",
    "\n",
    "![Jacobian](../misc/jacobian.png)\n",
    "\n",
    "The jaconbian matrix structure is as shown above. We see that the matrix is divided into equal parts in columns. We see that columns 0-119, 120-239, 240-359 repeat their structures.\n",
    "\n",
    "Lets consider first one third columns of the matrix. We see that in that sub matrix of the shape (420, 120), we see a diagonal line until row 359. This is for the odometry constraints (which are 360). As the odometry constraints are dependent only on consecutive 2 poses (vertices), we see that it is a diagonal gradient (line in graph). However, the slope is not 1 (it is 3), because we have residuals of y and theta also in the rows, to which the gradients wrt to x is zero. Hence, there is a discontinuity in the slant line and the slope is 3.\n",
    "\n",
    "From row 360 to 420, we see two slant lines, one from column 0 to 38 and another from 80 to 118. These are from loop closure constraints. Intuitively we can say that inital one third of poses (vertices) and last one third of poses (vertices) participate in loop closure (evident from groundtruth pose graph). Hence the first 40 and last 40 vertices must have non zero gradients in loop closure constraints. This is the reason we see those two slant gradients in the bootom.\n",
    "\n",
    "This structure repeats from second and last part (one thirds) of the columns also, which are partial derivatives wrt y and $ \\theta $ respectively. However, we can see that the third slant line which denotes the partial derivates of odometry edges with respect to $ \\theta_i $ has color changing along the line, which denotes changing values, whereas in the first and second lines (partial derivates of odometry edges wrt $ x_i $ and $ y_i $), the color is constant (two lines present), which denotes constant value (-1 and 1). This is because when we look at the partial derivates wrt $ x_i $ and $ y_i $, the values are either -1 ($ \\frac{\\delta x_{i+1}}{\\delta x_i} $), 0 or 1 ($ \\frac{\\delta x_i}{\\delta x_i} $) only. But the partial derivates wrt $ \\theta_i $ will have $ \\Delta x_i $, $ \\Delta y_i $, $ cos(\\theta_i) $ and $ sin(\\theta_i) $, which results into different values with changing edges.\n",
    "\n",
    "THe pose graph is not fully connected. It is evident from the jacobian matrix itself, because we see a lot of white space, which means the partial derivate of that specific residual element wrt pose element is 0. Which means that many poses are independent of other poses and are dependent only on the the consecutive poses (because we see two slant lines with different colors when we look closely). Hence, only the consecutive poses are connected to each. And at last few poses are connected to other poses which are not consecutive (loop closure edges. However those are also not spanned over all poses elements. Hence, the pose graph is not full connected.\n",
    "\n",
    "#### Question 4\n",
    "\n",
    "**SLAM frontend** basically deals with retrieving the LiDAR scans, RGB video stream and noisy pose data using odometry information. These data are retrieved from the sensors present. But since sensors are prone to different kinds of error and inconsistencies, they are not robust. Hence, this data is sent to the SLAM backend algorithm for optimizing purposes.\n",
    "\n",
    "**SLAM backend** deals with optimizing the given noisy pose data by reducing the drift in the noisy pose data and simultaneously updating the global map. Due to the noise present in the odometry information, there could be small drifts introduced in the robot trajectory, which keeps on accumulating over time and hence results into large drift. Hence, we need to optimize the poses/map of the robot. The noise in the pose data comes from the odometry information which is often prone to noise. Hence, this is the job of SLAM backend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
